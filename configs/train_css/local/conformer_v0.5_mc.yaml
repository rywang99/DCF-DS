# Note there's newer and better data. Do not download v1.2
train_dir: ./v1.2/100hrs/train
val_dir: ./v1.2/100hrs/val
out_dir: ./

train_set_cfg:
  sample_frac: 1.0
  max_urls: null  # null means no limit
val_set_cfg:
  sample_frac: 1.0
  max_urls: null  # null means no limit

# This model was actually trained with clip_gt_to_mixture: False, but we recommend to set it to True.

log_params_mlflow: True
log_metrics_mlflow: True

scheduler_step_every: [1, iterations]
scheduler_name: step_lr
scheduler_linear_warmup_decay_cfg:
  warmup: 10000
  decay: 260000
scheduler_step_lr_cfg:
  step_size: 1
  gamma: 1.0  # no decay

stop_after: [260000, iterations]
eval_every: [1000, iterations]
save_every: [1000, iterations]

global_batch_size: 256
learning_rate: 1e-5
weight_decay: 1e-2  # according to the paper set to 1e-2

# Large model per CSS with Conformer definition
conformer_css_cfg:
  nnet_conf:
    conformer_conf:
      attention_dim: 512  # default 256
      attention_heads: 8  # default 4
      num_blocks: 18  # default 16
